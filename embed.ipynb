{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f015154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files to process\n",
      "Processing file 1/5: ./data/FINANC_1_Istisna’a and Parallel Istisna’a (10).PDF\n",
      "  - Extracted 84 nodes from file\n",
      "  - Sample content: Financial Accounting Standard No. (10)Financial Accounting Standard No. (10)\n",
      "Istisna’a and Parallel ...\n",
      "Processing file 2/5: ./data/Ijarah (32).pdf\n",
      "  - Extracted 59 nodes from file\n",
      "  - Sample content:  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "AAOIFI Financial Accounting Standard 32 \n",
      "Ijarah \n",
      "  ...\n",
      "Processing file 3/5: ./data/FI922A_1_Murabaha and Other Deferred Payment Sales (28).PDF\n",
      "  - Extracted 29 nodes from file\n",
      "  - Sample content:  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "AAOIFI Financial Accounting Standard 28 \n",
      "Murabaha and Other Deferred Payment Sales \n",
      "  ...\n",
      "Processing file 4/5: ./data/FI5F55_1_Musharaka Financing(4).PDF\n",
      "  - Extracted 66 nodes from file\n",
      "  - Sample content: Financial Accounting Standard No. (4)Financial Accounting Standard No. (4)\n",
      "Musharaka FinancingMushar...\n",
      "Processing file 5/5: ./data/FI28ED_1_Salam and Parallel Salam (07).PDF\n",
      "  - Extracted 50 nodes from file\n",
      "  - Sample content: Financial Accounting Standard No. (7)Financial Accounting Standard No. (7)\n",
      "Salam and Parallel Salam ...\n",
      "\n",
      "Total nodes collected from all files: 288\n",
      "\n",
      "Testing retrieval with query: 'your test query here'\n",
      "Retrieved 20 chunks\n",
      "Top result score: 0.6199552284995716\n",
      "Top result content: 4 \n",
      " \n",
      "Ijarah MBT through gradual transfer – special considerations ................................................................. 27 \n",
      "In the books o...\n",
      "\n",
      "Saving vector database to ./vector_db_storage_only_5\n",
      "Vector database saved successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Directory containing your files\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")  # Adjust device as needed\n",
    "\n",
    "\n",
    "\n",
    "files_directory = \"./data/\"  # Replace with your directory path\n",
    "\n",
    "# Get all files in the directory\n",
    "file_paths = []\n",
    "for root, _, files in os.walk(files_directory):\n",
    "    for file in files:\n",
    "        # You can add file extension filters here if needed\n",
    "        # if file.endswith('.txt') or file.endswith('.pdf'):\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(file_paths)} files to process\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty list to collect all nodes\n",
    "all_nodes = []\n",
    "\n",
    "# Configure global settings for the RAG pipeline\n",
    "Settings.embed_model = embed_model  # Using your existing embed_model\n",
    "\n",
    "# Configure document splitters\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=20, \n",
    "    breakpoint_percentile_threshold=95, \n",
    "    embed_model=embed_model\n",
    ")\n",
    "base_splitter = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "# Process each file individually\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    try:\n",
    "        print(f\"Processing file {i+1}/{len(file_paths)}: {file_path}\")\n",
    "        \n",
    "        # Load a single document\n",
    "        documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "        \n",
    "        # Process document into nodes\n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "        \n",
    "        print(f\"  - Extracted {len(nodes)} nodes from file\")\n",
    "        if nodes:\n",
    "            print(f\"  - Sample content: {nodes[0].get_content()[:100]}...\")\n",
    "            \n",
    "        # Add nodes from this file to the collection\n",
    "        all_nodes.extend(nodes)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  - Error processing file {file_path}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTotal nodes collected from all files: {len(all_nodes)}\")\n",
    "\n",
    "# Create a vector index from all collected nodes\n",
    "index = VectorStoreIndex(all_nodes)\n",
    "\n",
    "# Configure a retriever with customized search parameters\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=20,  # Number of most relevant chunks to retrieve\n",
    ")\n",
    "\n",
    "# Test the vector database with a sample query\n",
    "test_query = \"your test query here\"  # Replace with your actual query\n",
    "print(f\"\\nTesting retrieval with query: '{test_query}'\")\n",
    "retrieval_results = retriever.retrieve(test_query)\n",
    "print(f\"Retrieved {len(retrieval_results)} chunks\")\n",
    "\n",
    "if retrieval_results:\n",
    "    print(f\"Top result score: {retrieval_results[0].score}\")\n",
    "    print(f\"Top result content: {retrieval_results[0].node.get_content()[:150]}...\")\n",
    "\n",
    "# Persist the vector database\n",
    "storage_path = \"./vector_db_storage_only_5\"\n",
    "print(f\"\\nSaving vector database to {storage_path}\")\n",
    "index.storage_context.persist(storage_path)\n",
    "print(\"Vector database saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
